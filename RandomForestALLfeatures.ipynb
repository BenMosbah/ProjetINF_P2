{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "## edit the link to be shorter and accessible from root folder\n",
    "train = pd.read_csv(\"data/train.csv\",header=None,names=['id','qid1','qid2','question1','question2','is_duplicate'])\n",
    "test = pd.read_csv(\"data/test.csv\",header=None,names=['test_id','qid1','qid2','question1','question2','is_duplicate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : Les données fournies ont l'air complètes et il y a pas l'air d'y avoir des fautes d'orthographe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a first method : Random forest with basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the metric that they want us to use : weighted_log_loss\n",
    "def weighted_log_loss(y_true, y_pred):\n",
    "    a = 0.165/0.37\n",
    "    b = (1-0.165)/(1-0.37)\n",
    "    score = a*y_true*np.log(y_pred+0.00001) + b*(1.0 - y_true)*np.log(1.0 - y_pred+0.00001)\n",
    "    return -np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the raw features that we will be working on :\n",
    "train_X, train_y = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "test_X = test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashing the questions...\n",
      "Number of unique questions: 58869\n",
      "Calculating common neighbor features...\n",
      "Calculating frequency features...\n"
     ]
    }
   ],
   "source": [
    "#Getting non-nlp features\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "NB_CORES = 10\n",
    "FREQ_UPPER_BOUND = 100\n",
    "NEIGHBOR_UPPER_BOUND = 5\n",
    "\n",
    "\n",
    "def create_question_hash(train_df, test_df):\n",
    "    train_qs = np.dstack([train_df[\"question1\"], train_df[\"question2\"]]).flatten()\n",
    "    test_qs = np.dstack([test_df[\"question1\"], test_df[\"question2\"]]).flatten()\n",
    "    all_qs = np.append(train_qs, test_qs)\n",
    "    all_qs = pd.DataFrame(all_qs)[0].drop_duplicates()\n",
    "    all_qs.reset_index(inplace=True, drop=True)\n",
    "    question_dict = pd.Series(all_qs.index.values, index=all_qs.values).to_dict()\n",
    "    return question_dict\n",
    "\n",
    "\n",
    "def get_hash(df, hash_dict):\n",
    "    df[\"qid1\"] = df[\"question1\"].map(hash_dict)\n",
    "    df[\"qid2\"] = df[\"question2\"].map(hash_dict)\n",
    "    return df.drop([\"question1\", \"question2\"], axis=1)\n",
    "\n",
    "\n",
    "def get_kcore_dict(df):\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(df.qid1)\n",
    "    edges = list(df[[\"qid1\", \"qid2\"]].to_records(index=False))\n",
    "    g.add_edges_from(edges)\n",
    "    g.remove_edges_from(g.selfloop_edges())\n",
    "\n",
    "    df_output = pd.DataFrame(data=g.nodes(), columns=[\"qid\"])\n",
    "    df_output[\"kcore\"] = 0\n",
    "    for k in range(2, NB_CORES + 1):\n",
    "        ck = nx.k_core(g, k=k).nodes()\n",
    "        print(\"kcore\", k)\n",
    "        df_output.ix[df_output.qid.isin(ck), \"kcore\"] = k\n",
    "\n",
    "    return df_output.to_dict()[\"kcore\"]\n",
    "\n",
    "\n",
    "def get_kcore_features(df, kcore_dict):\n",
    "    df[\"kcore1\"] = df[\"qid1\"].apply(lambda x: kcore_dict[x])\n",
    "    df[\"kcore2\"] = df[\"qid2\"].apply(lambda x: kcore_dict[x])\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_minmax(df, col):\n",
    "    sorted_features = np.sort(np.vstack([df[col + \"1\"], df[col + \"2\"]]).T)\n",
    "    df[\"min_\" + col] = sorted_features[:, 0]\n",
    "    df[\"max_\" + col] = sorted_features[:, 1]\n",
    "    return df.drop([col + \"1\", col + \"2\"], axis=1)\n",
    "\n",
    "\n",
    "def get_neighbors(train_df, test_df):\n",
    "    neighbors = defaultdict(set)\n",
    "    for df in [train_df, test_df]:\n",
    "        for q1, q2 in zip(df[\"qid1\"], df[\"qid2\"]):\n",
    "            neighbors[q1].add(q2)\n",
    "            neighbors[q2].add(q1)\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def get_neighbor_features(df, neighbors):\n",
    "    common_nc = df.apply(lambda x: len(neighbors[x.qid1].intersection(neighbors[x.qid2])), axis=1)\n",
    "    min_nc = df.apply(lambda x: min(len(neighbors[x.qid1]), len(neighbors[x.qid2])), axis=1)\n",
    "    df[\"common_neighbor_ratio\"] = common_nc / min_nc\n",
    "    df[\"common_neighbor_count\"] = common_nc.apply(lambda x: min(x, NEIGHBOR_UPPER_BOUND))\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_freq_features(df, frequency_map):\n",
    "    df[\"freq1\"] = df[\"qid1\"].map(lambda x: min(frequency_map[x], FREQ_UPPER_BOUND))\n",
    "    df[\"freq2\"] = df[\"qid2\"].map(lambda x: min(frequency_map[x], FREQ_UPPER_BOUND))\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Hashing the questions...\")\n",
    "question_dict = create_question_hash(train, test)\n",
    "train = get_hash(train, question_dict)\n",
    "test = get_hash(test, question_dict)\n",
    "print(\"Number of unique questions:\", len(question_dict))\n",
    "\n",
    "\n",
    "#print(\"Calculating kcore features...\")\n",
    "all_df = pd.concat([train, test])\n",
    "#kcore_dict = get_kcore_dict(all_df)\n",
    "#train = get_kcore_features(train, kcore_dict)\n",
    "#test = get_kcore_features(test, kcore_dict)\n",
    "#train = convert_to_minmax(train, \"kcore\")\n",
    "#test = convert_to_minmax(test, \"kcore\")\n",
    "\n",
    "\n",
    "print(\"Calculating common neighbor features...\")\n",
    "neighbors = get_neighbors(train, test)\n",
    "train = get_neighbor_features(train, neighbors)\n",
    "test = get_neighbor_features(test, neighbors)\n",
    "\n",
    "print(\"Calculating frequency features...\")\n",
    "frequency_map = dict(zip(*np.unique(np.vstack((all_df[\"qid1\"], all_df[\"qid2\"])), return_counts=True)))\n",
    "train = get_freq_features(train, frequency_map)\n",
    "test = get_freq_features(test, frequency_map)\n",
    "train = convert_to_minmax(train, \"freq\")\n",
    "test = convert_to_minmax(test, \"freq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_non_nlp_features = train.drop([\"id\",\"qid1\",\"qid2\",\"is_duplicate\"],axis=1)\n",
    "test_non_nlp_features = test.drop([\"test_id\",\"qid1\",\"qid2\",\"is_duplicate\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_neighbor_ratio</th>\n",
       "      <th>common_neighbor_count</th>\n",
       "      <th>min_freq</th>\n",
       "      <th>max_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   common_neighbor_ratio  common_neighbor_count  min_freq  max_freq\n",
       "0               0.833333                      5         6         6\n",
       "1               0.947368                      5        19        21\n",
       "2               0.947368                      5        19        19\n",
       "3               0.875000                      5         8         8\n",
       "4               0.785714                      5        14        15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_non_nlp_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_neighbor_ratio</th>\n",
       "      <th>common_neighbor_count</th>\n",
       "      <th>min_freq</th>\n",
       "      <th>max_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   common_neighbor_ratio  common_neighbor_count  min_freq  max_freq\n",
       "0                   0.00                      0         2         5\n",
       "1                   0.00                      0         1         5\n",
       "2                   0.00                      0         1         4\n",
       "3                   0.75                      3         4         4\n",
       "4                   0.00                      0         1        10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_non_nlp_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for train:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'question1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c1aff6fb5927>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extracting features for train:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"qid1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"qid2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"question1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"question2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;31m#train_df.to_csv(\"data/nlp_features_train.csv\", index=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-c1aff6fb5927>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#LA méthode qui extrait les features depuis la dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question1\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question2\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'question1'"
     ]
    }
   ],
   "source": [
    "#non-nlp features extraction\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz\n",
    "import distance\n",
    "\n",
    "SAFE_DIV = 0.0001\n",
    "STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "#Basic preprocessing :\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x\n",
    "\n",
    "#Getting token features\n",
    "def get_token_features(q1, q2):\n",
    "    token_features = [0.0]*10\n",
    "\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "\n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    return token_features\n",
    "\n",
    "\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a, b))\n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
    "\n",
    "#LA méthode qui extrait les features depuis la dataframe\n",
    "def extract_features(df):\n",
    "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "\n",
    "    print(\"token features...\")\n",
    "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
    "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
    "\n",
    "    print(\"fuzzy features..\")\n",
    "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "print(\"Extracting features for train:\")\n",
    "train_df = extract_features(train_X)\n",
    "train_df.drop([\"id\", \"qid1\", \"qid2\", \"question1\", \"question2\"], axis=1, inplace=True)\n",
    "#train_df.to_csv(\"data/nlp_features_train.csv\", index=False)\n",
    "\n",
    "print(\"Extracting features for test:\")\n",
    "test_df = extract_features(test_X)\n",
    "test_df.drop([\"test_id\",\"qid1\",\"qid2\", \"question1\", \"question2\"], axis=1, inplace=True)\n",
    "#test_df.to_csv(\"data/nlp_features_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>92</td>\n",
       "      <td>68</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>0.312498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>0.269841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "0  0.000000  0.000000  0.999980  0.624992  0.624992  0.357140             0   \n",
       "1  0.249994  0.166664  0.399992  0.399992  0.333330  0.249998             0   \n",
       "2  0.799984  0.399996  0.249994  0.199996  0.499995  0.312498             1   \n",
       "3  0.999967  0.749981  0.999950  0.666644  0.833319  0.833319             1   \n",
       "4  0.199996  0.199996  0.333328  0.333328  0.272725  0.249998             0   \n",
       "\n",
       "   first_word_eq  abs_len_diff  mean_len  token_set_ratio  token_sort_ratio  \\\n",
       "0              1             6      11.0               92                68   \n",
       "1              1             3      10.5               67                54   \n",
       "2              0             6      13.0               69                58   \n",
       "3              0             0       6.0               92                88   \n",
       "4              1             1      11.5               58                53   \n",
       "\n",
       "   fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0          60                  84              0.368421  \n",
       "1          56                  57              0.208333  \n",
       "2          61                  61              0.269841  \n",
       "3          81                  76              0.500000  \n",
       "4          52                  53              0.196721  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222220</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id   cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  \\\n",
       "0        0  0.499988  0.399992  0.666644  0.399992  0.571420  0.399996   \n",
       "1        1  0.999950  0.999950  0.999967  0.749981  0.999980  0.833319   \n",
       "2        2  0.999975  0.999975  0.749981  0.599988  0.874989  0.777769   \n",
       "3        3  0.599988  0.499992  0.999975  0.999975  0.777769  0.699993   \n",
       "4        4  0.499988  0.399992  0.000000  0.000000  0.222220  0.199998   \n",
       "\n",
       "   last_word_eq  first_word_eq  abs_len_diff  mean_len  token_set_ratio  \\\n",
       "0             0              1             3       8.5               71   \n",
       "1             1              1             1       5.5              100   \n",
       "2             1              0             1       8.5               91   \n",
       "3             1              1             1       9.5               70   \n",
       "4             1              0             1       9.5               56   \n",
       "\n",
       "   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0                71          62                  62              0.250000  \n",
       "1                90          90                  79              0.517241  \n",
       "2                88          88                  87              0.700000  \n",
       "3                61          62                  57              0.296296  \n",
       "4                51          62                  63              0.380952  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all_features = pd.concat([train_df,train_non_nlp_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>common_neighbor_ratio</th>\n",
       "      <th>common_neighbor_count</th>\n",
       "      <th>min_freq</th>\n",
       "      <th>max_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>92</td>\n",
       "      <td>68</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>0.312498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "0  0.000000  0.000000  0.999980  0.624992  0.624992  0.357140             0   \n",
       "1  0.249994  0.166664  0.399992  0.399992  0.333330  0.249998             0   \n",
       "2  0.799984  0.399996  0.249994  0.199996  0.499995  0.312498             1   \n",
       "3  0.999967  0.749981  0.999950  0.666644  0.833319  0.833319             1   \n",
       "4  0.199996  0.199996  0.333328  0.333328  0.272725  0.249998             0   \n",
       "\n",
       "   first_word_eq  abs_len_diff  mean_len  token_set_ratio  token_sort_ratio  \\\n",
       "0              1             6      11.0               92                68   \n",
       "1              1             3      10.5               67                54   \n",
       "2              0             6      13.0               69                58   \n",
       "3              0             0       6.0               92                88   \n",
       "4              1             1      11.5               58                53   \n",
       "\n",
       "   fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \\\n",
       "0          60                  84              0.368421   \n",
       "1          56                  57              0.208333   \n",
       "2          61                  61              0.269841   \n",
       "3          81                  76              0.500000   \n",
       "4          52                  53              0.196721   \n",
       "\n",
       "   common_neighbor_ratio  common_neighbor_count  min_freq  max_freq  \n",
       "0                   0.00                      0         2         5  \n",
       "1                   0.00                      0         1         5  \n",
       "2                   0.00                      0         1         4  \n",
       "3                   0.75                      3         4         4  \n",
       "4                   0.00                      0         1        10  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all_features = pd.concat([test_df,test_non_nlp_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>common_neighbor_ratio</th>\n",
       "      <th>common_neighbor_count</th>\n",
       "      <th>min_freq</th>\n",
       "      <th>max_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222220</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id   cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  \\\n",
       "0        0  0.499988  0.399992  0.666644  0.399992  0.571420  0.399996   \n",
       "1        1  0.999950  0.999950  0.999967  0.749981  0.999980  0.833319   \n",
       "2        2  0.999975  0.999975  0.749981  0.599988  0.874989  0.777769   \n",
       "3        3  0.599988  0.499992  0.999975  0.999975  0.777769  0.699993   \n",
       "4        4  0.499988  0.399992  0.000000  0.000000  0.222220  0.199998   \n",
       "\n",
       "   last_word_eq  first_word_eq  abs_len_diff  mean_len  token_set_ratio  \\\n",
       "0             0              1             3       8.5               71   \n",
       "1             1              1             1       5.5              100   \n",
       "2             1              0             1       8.5               91   \n",
       "3             1              1             1       9.5               70   \n",
       "4             1              0             1       9.5               56   \n",
       "\n",
       "   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \\\n",
       "0                71          62                  62              0.250000   \n",
       "1                90          90                  79              0.517241   \n",
       "2                88          88                  87              0.700000   \n",
       "3                61          62                  57              0.296296   \n",
       "4                51          62                  63              0.380952   \n",
       "\n",
       "   common_neighbor_ratio  common_neighbor_count  min_freq  max_freq  \n",
       "0               0.833333                      5         6         6  \n",
       "1               0.947368                      5        19        21  \n",
       "2               0.947368                      5        19        19  \n",
       "3               0.875000                      5         8         8  \n",
       "4               0.785714                      5        14        15  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Classifier log loss error: -0.6611652049134563\n"
     ]
    }
   ],
   "source": [
    "#Training the Random Forest\n",
    "import itertools as itertools\n",
    "import sklearn as skl\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, make_scorer, confusion_matrix\n",
    "\n",
    "# Cross validation with Grid Search to optimize hyper parameters\n",
    "cv_sets = KFold(n_splits=10, random_state=0)\n",
    "scorer = make_scorer(weighted_log_loss, greater_is_better=False)\n",
    "\n",
    "# varying class_weight to penalize False Positives more \n",
    "grid = GridSearchCV(RandomForestClassifier(200, random_state=0),\n",
    "                        scoring=scorer,\n",
    "                        cv = cv_sets,\n",
    "                        param_grid={\"class_weight\": [{0:100, 1:1}, {0:10, 1:1}, {0:1, 1:1}]})\n",
    "\n",
    "# Training Random Forest Classifier with full training dataset\n",
    "grid.fit(train_all_features, train_y)\n",
    "print(\"Random Forests Classifier log loss error: {}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate predictions and submit on kaggle\n",
    "#test_all_features = test_all_features.drop('test_id',axis=1)\n",
    "prob_y = grid.predict_proba(test_all_features)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_X['test_id']\n",
    "submission['Score'] = prob_y[:,1]\n",
    "submission.to_csv(\"submissions/submission_rf_AllFeatures.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
