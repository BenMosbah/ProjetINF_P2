{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "## edit the link to be shorter and accessible from root folder\n",
    "train = pd.read_csv(\"data/train.csv\",header=None,names=['id','qid1','qid2','question1','question2','is_duplicate'])\n",
    "test = pd.read_csv(\"data/test.csv\",header=None,names=['test_id','qid1','qid2','question1','question2','is_duplicate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : Les données fournies ont l'air complètes et il y a pas l'air d'y avoir des fautes d'orthographe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a first method : Random forest with basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the metric that they want us to use : weighted_log_loss\n",
    "def weighted_log_loss(y_true, y_pred):\n",
    "    a = 0.165/0.37\n",
    "    b = (1-0.165)/(1-0.37)\n",
    "    score = a*y_true*np.log(y_pred+0.00001) + b*(1.0 - y_true)*np.log(1.0 - y_pred+0.00001)\n",
    "    return -np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the raw features that we will be working on :\n",
    "train_X, train_y = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "test_X = test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for train:\n",
      "Extracting features for test:\n",
      "token features...\n",
      "fuzzy features..\n"
     ]
    }
   ],
   "source": [
    "#non-nlp features extraction\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz\n",
    "import distance\n",
    "\n",
    "SAFE_DIV = 0.0001\n",
    "STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "#Basic preprocessing :\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x\n",
    "\n",
    "#Getting token features\n",
    "def get_token_features(q1, q2):\n",
    "    token_features = [0.0]*10\n",
    "\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "\n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    return token_features\n",
    "\n",
    "\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a, b))\n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
    "\n",
    "#LA méthode qui extrait les features depuis la dataframe\n",
    "def extract_features(df):\n",
    "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "\n",
    "    print(\"token features...\")\n",
    "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
    "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
    "\n",
    "    print(\"fuzzy features..\")\n",
    "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "print(\"Extracting features for train:\")\n",
    "train_df = extract_features(train_X)\n",
    "train_df.drop([\"id\", \"qid1\", \"qid2\", \"question1\", \"question2\"], axis=1, inplace=True)\n",
    "#train_df.to_csv(\"data/nlp_features_train.csv\", index=False)\n",
    "\n",
    "print(\"Extracting features for test:\")\n",
    "test_df = extract_features(test_X)\n",
    "test_df.drop([\"qid1\",\"qid2\", \"question1\", \"question2\"], axis=1, inplace=True)\n",
    "#test_df.to_csv(\"data/nlp_features_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>92</td>\n",
       "      <td>68</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>0.312498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>0.269841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "0  0.000000  0.000000  0.999980  0.624992  0.624992  0.357140             0   \n",
       "1  0.249994  0.166664  0.399992  0.399992  0.333330  0.249998             0   \n",
       "2  0.799984  0.399996  0.249994  0.199996  0.499995  0.312498             1   \n",
       "3  0.999967  0.749981  0.999950  0.666644  0.833319  0.833319             1   \n",
       "4  0.199996  0.199996  0.333328  0.333328  0.272725  0.249998             0   \n",
       "\n",
       "   first_word_eq  abs_len_diff  mean_len  token_set_ratio  token_sort_ratio  \\\n",
       "0              1             6      11.0               92                68   \n",
       "1              1             3      10.5               67                54   \n",
       "2              0             6      13.0               69                58   \n",
       "3              0             0       6.0               92                88   \n",
       "4              1             1      11.5               58                53   \n",
       "\n",
       "   fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0          60                  84              0.368421  \n",
       "1          56                  57              0.208333  \n",
       "2          61                  61              0.269841  \n",
       "3          81                  76              0.500000  \n",
       "4          52                  53              0.196721  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222220</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id   cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  \\\n",
       "0        0  0.499988  0.399992  0.666644  0.399992  0.571420  0.399996   \n",
       "1        1  0.999950  0.999950  0.999967  0.749981  0.999980  0.833319   \n",
       "2        2  0.999975  0.999975  0.749981  0.599988  0.874989  0.777769   \n",
       "3        3  0.599988  0.499992  0.999975  0.999975  0.777769  0.699993   \n",
       "4        4  0.499988  0.399992  0.000000  0.000000  0.222220  0.199998   \n",
       "\n",
       "   last_word_eq  first_word_eq  abs_len_diff  mean_len  token_set_ratio  \\\n",
       "0             0              1             3       8.5               71   \n",
       "1             1              1             1       5.5              100   \n",
       "2             1              0             1       8.5               91   \n",
       "3             1              1             1       9.5               70   \n",
       "4             1              0             1       9.5               56   \n",
       "\n",
       "   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0                71          62                  62              0.250000  \n",
       "1                90          90                  79              0.517241  \n",
       "2                88          88                  87              0.700000  \n",
       "3                61          62                  57              0.296296  \n",
       "4                51          62                  63              0.380952  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Classifier log loss error: -2.3874208706073303\n"
     ]
    }
   ],
   "source": [
    "#Training the Random Forest\n",
    "import itertools as itertools\n",
    "import sklearn as skl\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, make_scorer, confusion_matrix\n",
    "\n",
    "# Cross validation with Grid Search to optimize hyper parameters\n",
    "cv_sets = KFold(n_splits=10, random_state=0)\n",
    "scorer = make_scorer(weighted_log_loss, greater_is_better=False)\n",
    "\n",
    "# varying class_weight to penalize False Positives more \n",
    "grid = GridSearchCV(RandomForestClassifier(200, random_state=0),\n",
    "                        scoring=scorer,\n",
    "                        cv = cv_sets,\n",
    "                        param_grid={\"class_weight\": [{0:100, 1:1}, {0:10, 1:1}, {0:1, 1:1}]})\n",
    "\n",
    "# Training Random Forest Classifier with full training dataset\n",
    "grid.fit(train_df, train_y)\n",
    "print(\"Random Forests Classifier log loss error: {}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions and submit on kaggle\n",
    "test_df = test_df.drop('test_id',axis=1)\n",
    "prob_y = grid.predict_proba(test_df)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_X['test_id']\n",
    "submission['Score'] = prob_y[:,1]\n",
    "submission.to_csv(\"submissions/submission_rf_nonNLP_features.csv\", index=False)\n",
    "#C'est de la merde, ça fait un score de 0,8 alors que la baseline est à 0.6..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
